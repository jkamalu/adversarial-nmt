{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using an LSTM as the decoding mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\n",
      "To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "import torch\n",
    "from torch.cuda import is_available\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from modules.lib.huggingface import transformers\n",
    "from modules.data import TextDataset, Collator\n",
    "from modules.model import Embeddings, Encoder, Decoder, Discriminator, Hook \n",
    "from modules import utils\n",
    "\n",
    "# TODO replace: \n",
    "experiment = \"gru-decoding\"\n",
    "config = utils.load_config(\"config/{}.yml\".format(\"gru_decoder_none\"))\n",
    "\n",
    "if is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"WARNING: CUDA IS NOT AVAILABLE\".format(device))\n",
    "    \n",
    "ckpt_dir = \"experiments/{}/checkpoints\".format(experiment)\n",
    "runs_dir = \"experiments/{}/tensorboard\".format(experiment)\n",
    "\n",
    "try: \n",
    "    os.makedirs(ckpt_dir)\n",
    "    os.makedirs(runs_dir)\n",
    "except FileExistsError: \n",
    "    print(\"File already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Loading in pre-saved file: /juice/scr/scr110/scr/nlp/mtl_bert/unidirectional-NMT/data/europarl-v7/data.train.pkl\n",
      "**Loading in pre-saved file: /juice/scr/scr110/scr/nlp/mtl_bert/unidirectional-NMT/data/europarl-v7/data.val.pkl\n"
     ]
    }
   ],
   "source": [
    "# Build tokenizer for English and French\n",
    "tokenizer_en = transformers.RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenizer_fr = transformers.CamembertTokenizer.from_pretrained('camembert-base')\n",
    "\n",
    "# Build TextDataset for train and valid\n",
    "data_path = utils.data_path(\"europarl-v7\")\n",
    "dataset_train = TextDataset(\n",
    "    data_path, \n",
    "    tokenizer_en, \n",
    "    tokenizer_fr, \n",
    "    training=True, \n",
    "    minlen=config[\"minlen\"],\n",
    "    maxlen=config[\"maxlen\"]\n",
    ")\n",
    "dataset_valid = TextDataset(\n",
    "    data_path, \n",
    "    tokenizer_en, \n",
    "    tokenizer_fr, \n",
    "    training=False, \n",
    "    minlen=config[\"minlen\"],\n",
    "    maxlen=config[\"maxlen\"]\n",
    ")\n",
    "\n",
    "# Build DataLoader for train and valid\n",
    "collator = Collator(maxlen=config[\"maxlen\"])\n",
    "dataloader_train = DataLoader(dataset_train, **config[\"data_loader\"], collate_fn=collator)\n",
    "dataloader_valid = DataLoader(dataset_valid, **config[\"data_loader\"], collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Model\n",
    "\n",
    "1. Using the Output Embedding to Improve Language Models - http://arxiv.org/abs/1608.05859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Init BERT encoder w/pretrained weights\n",
    "bert_en = Encoder.init_bert(\"english\").to(device=device)\n",
    "bert_fr = Encoder.init_bert(\"french\").to(device=device)\n",
    "\n",
    "# Init embeddings w/pretrained weights from BERT encoder\n",
    "embeddings_en = Embeddings.from_pretrained(bert_en.model.get_input_embeddings()).to(device=device)\n",
    "embeddings_fr = Embeddings.from_pretrained(bert_fr.model.get_input_embeddings()).to(device=device)\n",
    "\n",
    "if config[\"use_bert\"]:\n",
    "    # Use BERT encoder\n",
    "    encoder_en = bert_en\n",
    "    encoder_fr = bert_fr\n",
    "else:\n",
    "    # Init vanilla Transformer encoder w/pretrained embeddings from BERT encoder\n",
    "    del bert_en\n",
    "    del bert_fr\n",
    "    encoder_en = Encoder.init_vanilla(**config[\"encoder\"], embeddings=embeddings_en).to(device=device)\n",
    "    encoder_fr = Encoder.init_vanilla(**config[\"encoder\"], embeddings=embeddings_fr).to(device=device)\n",
    "\n",
    "# Init Hooks for encoder layers\n",
    "hooks_en = [Hook(layer[1]) for layer in list(encoder_en.named_modules())]\n",
    "hooks_fr = [Hook(layer[1]) for layer in list(encoder_fr.named_modules())]\n",
    "    \n",
    "# Init vanilla Transformer decoder w/pretrained embeddings from BERT encoder\n",
    "decoder_en = Decoder.init_from_config(**config[\"decoder\"], embeddings=embeddings_en).to(device=device)\n",
    "decoder_fr = Decoder.init_from_config(**config[\"decoder\"], embeddings=embeddings_fr).to(device=device)\n",
    "\n",
    "# Init Discriminator(s)\n",
    "discriminators = {}\n",
    "for regularization in config[\"regularization\"][\"type\"]:\n",
    "    discriminators[regularization] = Discriminator(regularization, **config[\"discriminator\"]).to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define loss/metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def loss_fn(real_en, real_fr, pred_en, pred_fr, real_pred_ys={}, ignore_index=1):\n",
    "    '''\n",
    "    Adversarial Loss: standard loss with binary cross entropy on top of the discriminator outputs\n",
    "    '''\n",
    "    cce_loss = torch.nn.CrossEntropyLoss(ignore_index=ignore_index)\n",
    "    \n",
    "    loss_en2fr = cce_loss(pred_fr.transpose(1,2), real_fr)\n",
    "    loss_fr2en = cce_loss(pred_en.transpose(1,2), real_en)\n",
    "    \n",
    "    bce_loss = torch.nn.BCEWithLogitsLoss()\n",
    "    reg_losses = defaultdict(lambda: torch.tensor(0.0))\n",
    "    for regularization in real_pred_ys:\n",
    "        real_y, pred_y = real_pred_ys[regularization]\n",
    "        reg_losses[regularization] = bce_loss(pred_y, real_y)\n",
    "\n",
    "    return loss_en2fr + loss_fr2en + torch.sum(torch.tensor(list(reg_losses.values()))), loss_en2fr, loss_fr2en, reg_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def exact_match(pred, real, ignore_index=1):\n",
    "    '''\n",
    "    Evaluate percent exact match between predictions and ground truth\n",
    "    '''\n",
    "    mask = real != ignore_index\n",
    "    return torch.sum((pred == real) * mask).item() / torch.sum(mask).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining training logic\n",
    "\n",
    "1. What Does BERT Look At? An Analysis of BERT's Attention - https://arxiv.org/abs/1906.04341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     10,
     22,
     27
    ]
   },
   "outputs": [],
   "source": [
    "def get_optimizer(encoder_en, encoder_fr, decoder_en, decoder_fr, discriminators, **kwargs):\n",
    "    params = (\n",
    "        list(encoder_en.parameters()) + list(encoder_fr.parameters()) +\n",
    "        list(decoder_fr.parameters()) + list(decoder_en.parameters())\n",
    "    )\n",
    "    for regularization in discriminators:\n",
    "        if discriminators[regularization] is not None and regularization != \"none\":\n",
    "            params += list(discriminators[regularization].parameters())\n",
    "    return Adam(params, **kwargs)\n",
    "\n",
    "def switch_trainable(model, step):\n",
    "    switch = step % 2 == 0\n",
    "    if len(model[\"discriminators\"]) > 0:\n",
    "        for module in model:\n",
    "            if module == \"discriminators\":\n",
    "                for regularization in model[module]:\n",
    "                    for param in model[module][regularization].parameters():\n",
    "                        param.requires_grad = not switch\n",
    "            elif module in (\"encoder_en, encoder_fr\"):\n",
    "                for param in model[module].parameters():\n",
    "                    param.requires_grad = switch\n",
    "\n",
    "def save_weights(model, step):\n",
    "    for name, module in model.items(): \n",
    "        if module:\n",
    "            torch.save(module.state_dict(), os.path.join(ckpt_dir, \"{}.{}.pt\".format(step, name)))\n",
    "        \n",
    "def forward(model, batch):\n",
    "        # Unpack batch and move to device\n",
    "        batch_en, batch_fr = batch\n",
    "        sents_en, sents_no_eos_en, lengths_en = map(lambda t: t.to(device=device), batch_en)\n",
    "        sents_fr, sents_no_eos_fr, lengths_fr = map(lambda t: t.to(device=device), batch_fr)\n",
    "\n",
    "        # Encode English to French\n",
    "        enc_out_en = encoder_en(sents_en, lengths=lengths_en)\n",
    "        # Decoder English to French\n",
    "        decoder_fr.model.init_state(sents_en)\n",
    "        dec_out_fr = decoder_fr(sents_no_eos_fr, enc_out_en, memory_lengths=lengths_en)\n",
    "\n",
    "        # Encoder French to English\n",
    "        enc_out_fr = encoder_fr(sents_fr, lengths=lengths_fr)\n",
    "        # Decoder French to English\n",
    "        decoder_en.model.init_state(sents_fr)\n",
    "        dec_out_en = decoder_en(sents_no_eos_en, enc_out_fr, memory_lengths=lengths_fr)\n",
    "        \n",
    "        return sents_en, sents_fr, enc_out_en, enc_out_fr, dec_out_en, dec_out_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train(): \n",
    "    ''' \n",
    "    Train the encoding and decoding models. User needs to pass in a valid iterator over the data,\n",
    "    and also specify a type of adversarial regularization. regularize = [\"hidden\", \"attention\", \"both\"]\n",
    "    '''\n",
    "    model = {\n",
    "        \"encoder_en\": encoder_en,\n",
    "        \"encoder_fr\": encoder_fr,\n",
    "        \"decoder_en\": decoder_en,\n",
    "        \"decoder_fr\": decoder_fr,\n",
    "        \"discriminators\": discriminators,\n",
    "    }\n",
    "    \n",
    "    optimizer = get_optimizer(**model, **config[\"adam\"])\n",
    "    \n",
    "    writer = SummaryWriter(runs_dir)\n",
    "                                                   \n",
    "    for batch_i, batch in enumerate(dataloader_train):\n",
    "        \n",
    "        # Clear optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Alternate trainable for encoder/decoder \n",
    "        # and discriminator parameters\n",
    "        switch_trainable(model, batch_i)\n",
    "\n",
    "        # Save weights and continue training\n",
    "        if batch_i > 0 and batch_i % config[\"checkpoint_frequency\"] == 0:\n",
    "            save_weights(model, batch_i)\n",
    "        \n",
    "        # Save weights and terminate training\n",
    "        if batch_i >= config[\"max_step_num\"]:\n",
    "            save_weights(model, batch_i)\n",
    "            break\n",
    "        \n",
    "        # Unpack the batch, run the encoders, run the decoders\n",
    "        sents_en, sents_fr, enc_out_en, enc_out_fr, dec_out_en, dec_out_fr = forward(model, batch)\n",
    "        \n",
    "        return \n",
    "        \n",
    "        # Initial default values for regularization \n",
    "        real_pred_ys = {}\n",
    "        switch = batch_i % 2 == 0\n",
    "        y_real = [float(switch)] * config[\"batch_size\"] + [float(not switch)] * config[\"batch_size\"]\n",
    "        y_real = torch.tensor(y_real).unsqueeze(-1).to(device=device)\n",
    "        \n",
    "        # Gather attention discriminator labels/predictions\n",
    "        if \"attention\" in model[\"discriminators\"]:\n",
    "            \n",
    "\n",
    "            if (config[\"regularization\"][\"n_affine\"] == 12):\n",
    "                attention_en = torch.cat(list(utils.extract_attention_scores(hooks_en).values()), dim=1)\n",
    "                attention_fr = torch.cat(list(utils.extract_attention_scores(hooks_fr).values()), dim=1)\n",
    "                attention_en = attention_en.view(config[\"batch_size\"], config[\"regularization\"][\"n_affine\"], -1)\n",
    "                attention_fr = attention_fr.view(config[\"batch_size\"], config[\"regularization\"][\"n_affine\"], -1)\n",
    "            else: \n",
    "                # NOTE: this has to be changed individually if different attention needs want to be used \n",
    "                # we only investiage the 7th attention layer \n",
    "                attention_en = utils.extract_attention_scores(hooks_en)[6].view(config[\"batch_size\"], 1, -1)\n",
    "                attention_fr = utils.extract_attention_scores(hooks_fr)[6].view(config[\"batch_size\"], 1, -1)\n",
    "            \n",
    "            y_attn_pred_en = model[\"discriminators\"][\"attention\"](attention_en)\n",
    "            y_attn_pred_fr = model[\"discriminators\"][\"attention\"](attention_fr)\n",
    "            y_attn_pred = torch.cat([y_attn_pred_en, y_attn_pred_fr])\n",
    "            real_pred_ys[\"attention\"] = y_real, y_attn_pred\n",
    "            \n",
    "        # Gather hidden discriminator labels/predictions\n",
    "        if \"hidden\" in model[\"discriminators\"]:\n",
    "            # Use the pooled outputs of the encoders for regularization\n",
    "            y_hddn_pred_en = model[\"discriminators\"][\"hidden\"](enc_out_en)\n",
    "            y_hddn_pred_fr = model[\"discriminators\"][\"hidden\"](enc_out_fr)\n",
    "            y_hddn_pred = torch.cat([y_hddn_pred_en, y_hddn_pred_fr])\n",
    "            real_pred_ys[\"hidden\"] = y_real, y_hddn_pred\n",
    "\n",
    "        loss, loss_en2fr, loss_fr2en, reg_losses = loss_fn(\n",
    "            sents_en[:, 1:], sents_fr[:, 1:],\n",
    "            dec_out_en, dec_out_fr, \n",
    "            real_pred_ys,\n",
    "            ignore_index=1\n",
    "        )\n",
    "        \n",
    "        # Optimize trainable parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Write training losses/metrics to stdout and tensorboard\n",
    "        if batch_i % config[\"logging_frequency\"] == 0:\n",
    "            print(\"Batch {}: Loss {}\".format(batch_i, loss.item()))\n",
    "            cce_metrics = {\"en-fr\": loss_en2fr.item(), \"fr-en\": loss_fr2en.item()}\n",
    "            utils.write_to_tensorboard(\"CCE\", cce_metrics, training=True, step=batch_i, writer=writer)\n",
    "            bce_metrics = {\"attn\": reg_losses[\"attention\"].item(), \"hddn\": reg_losses[\"hidden\"].item()}\n",
    "            utils.write_to_tensorboard(\"BCE\", bce_metrics, training=True, step=batch_i, writer=writer)\n",
    "\n",
    "        # Running validation script  \n",
    "        if batch_i > 0 and batch_i % config[\"val_frequency\"] == 0:\n",
    "            _loss_en2fr_val = []\n",
    "            _loss_fr2en_val = []                \n",
    "\n",
    "            _bleu_en2fr = []\n",
    "            _bleu_fr2en = []\n",
    "\n",
    "            _em_en2fr = []\n",
    "            _em_fr2en = []\n",
    "            with torch.no_grad():\n",
    "                \n",
    "\n",
    "                for batch_j, batch in enumerate(dataloader_valid):\n",
    "                    \n",
    "                    if (batch_j == config[\"n_valid\"]):\n",
    "                        break\n",
    "                    \n",
    "                    # Unpack the batch, run the encoders, run the decoders\n",
    "                    sents_en, sents_fr, enc_out_en, enc_out_fr, dec_out_en, dec_out_fr = forward(model, batch)\n",
    "                    \n",
    "                    # Calculate BLUE Scores, EM and Perplexity\n",
    "                    preds_fr = torch.argmax(dec_out_fr, dim=-1)\n",
    "                    preds_en = torch.argmax(dec_out_en, dim=-1)\n",
    "                    \n",
    "                    _, loss_en2fr_val, loss_fr2en_val, _ = loss_fn(\n",
    "                        sents_en[:, 1:], sents_fr[:, 1:],\n",
    "                        dec_out_en, dec_out_fr,\n",
    "                        ignore_index=1\n",
    "                    )\n",
    "                    _loss_en2fr_val.append(loss_en2fr_val.item())\n",
    "                    _loss_fr2en_val.append(loss_fr2en_val.item())\n",
    "                    \n",
    "                    for idx in range(config[\"batch_size\"]):\n",
    "                        text_real_fr = tokenizer_fr.convert_tokens_to_string(sents_fr[idx, 1:-1].tolist())\n",
    "                        text_pred_fr = tokenizer_fr.convert_tokens_to_string(preds_fr[idx, 0:-1].tolist())\n",
    "                        _bleu_en2fr.append(sentence_bleu([text_real_fr], text_pred_fr))\n",
    "                        \n",
    "                        text_real_en = tokenizer_en.decode(sents_en[idx, 1:-1].tolist())\n",
    "                        text_pred_en = tokenizer_en.decode(preds_en[idx, 0:-1].tolist())\n",
    "                        _bleu_fr2en.append(sentence_bleu([text_real_en], text_pred_en))\n",
    "                    \n",
    "\n",
    "                    _em_en2fr.append(exact_match(preds_fr[:, 0:-1], sents_fr[:, 1:-1]))\n",
    "                    _em_fr2en.append(exact_match(preds_en[:, 0:-1], sents_en[:, 1:-1]))\n",
    "\n",
    "            avg_em_en2fr = sum(_em_en2fr) / len(_em_en2fr)\n",
    "            avg_em_fr2en = sum(_em_fr2en) / len(_em_fr2en)\n",
    "            avg_bleu_en2fr = sum(_bleu_en2fr) / len(_bleu_en2fr)\n",
    "            avg_bleu_fr2en = sum(_bleu_fr2en) / len(_bleu_fr2en)\n",
    "            avg_loss_en2fr_val = sum(_loss_en2fr_val) / len(_loss_en2fr_val)\n",
    "            avg_loss_fr2en_val = sum(_loss_fr2en_val) / len(_loss_fr2en_val)\n",
    "\n",
    "            bleu_metrics = {\"en-fr\": avg_bleu_en2fr, \"fr-en\": avg_bleu_fr2en}\n",
    "            utils.write_to_tensorboard(\"BLEU\", bleu_metrics, training=False, step=batch_i, writer=writer)\n",
    "\n",
    "            em_metrics = {\"en-fr\": avg_em_en2fr, \"fr-en\": avg_em_fr2en}\n",
    "            utils.write_to_tensorboard(\"EM\", em_metrics, training=False, step=batch_i, writer=writer)\n",
    "\n",
    "            loss_val_metrics = {\"en-fr\": avg_loss_en2fr_val, \"fr-en\": avg_loss_fr2en_val}\n",
    "            utils.write_to_tensorboard(\"CCE\", loss_val_metrics, training=False, step=batch_i, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape\n",
      "torch.Size([8, 49])\n",
      "hidden shape\n",
      "torch.Size([8, 50, 768])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-370ef8d6f316>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Unpack the batch, run the encoders, run the decoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0msents_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents_fr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out_fr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_out_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_out_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d45d7d3846ed>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Decoder English to French\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mdecoder_fr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mdec_out_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_fr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents_no_eos_fr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Encoder French to English\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/mtl_bert_environment/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/scr110/scr/nlp/mtl_bert/unidirectional-NMT/modules/model/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/mtl_bert_environment/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/scr110/scr/nlp/mtl_bert/unidirectional-NMT/modules/model/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mgru_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inside of forward GRU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "train()\n",
    "\n",
    "# Trying to figure out embedding issue; and dimension of hidden and input to match up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
