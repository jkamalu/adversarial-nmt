batch_size: &batch_size 16

data_loader:
    batch_size: *batch_size
    shuffle: True
    num_workers: 4

small_transformer:
    num_layers: 6
    d_model: 768
    heads: 8
    d_ff: 2048
    copy_attn: False
    self_attn_type: scaled-dot
    dropout: 0.1
    attention_dropout: 0.1
    max_relative_positions: 0
    aan_useffn: False 